# SenseVoice

github [repo](https://github.com/FunAudioLLM/SenseVoice) : https://github.com/FunAudioLLM/SenseVoice

SenseVoiceæ˜¯å…·æœ‰éŸ³é¢‘ç†è§£èƒ½åŠ›çš„éŸ³é¢‘åŸºç¡€æ¨¡å‹ï¼ŒåŒ…æ‹¬è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ã€è¯­ç§è¯†åˆ«ï¼ˆLIDï¼‰ã€è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ï¼ˆSERï¼‰å’Œå£°å­¦äº‹ä»¶åˆ†ç±»ï¼ˆAECï¼‰æˆ–å£°å­¦äº‹ä»¶æ£€æµ‹ï¼ˆAEDï¼‰ã€‚æœ¬é¡¹ç›®æä¾›SenseVoiceæ¨¡å‹çš„ä»‹ç»ä»¥åŠåœ¨å¤šä¸ªä»»åŠ¡æµ‹è¯•é›†ä¸Šçš„benchmarkï¼Œä»¥åŠä½“éªŒæ¨¡å‹æ‰€éœ€çš„ç¯å¢ƒå®‰è£…çš„ä¸æ¨ç†æ–¹å¼ã€‚

# æ ¸å¿ƒåŠŸèƒ½ ğŸ¯
**SenseVoice**ä¸“æ³¨äºé«˜ç²¾åº¦å¤šè¯­è¨€è¯­éŸ³è¯†åˆ«ã€æƒ…æ„Ÿè¾¨è¯†å’ŒéŸ³é¢‘äº‹ä»¶æ£€æµ‹
- **å¤šè¯­è¨€è¯†åˆ«ï¼š** é‡‡ç”¨è¶…è¿‡40ä¸‡å°æ—¶æ•°æ®è®­ç»ƒï¼Œæ”¯æŒè¶…è¿‡50ç§è¯­è¨€ï¼Œè¯†åˆ«æ•ˆæœä¸Šä¼˜äºWhisperæ¨¡å‹ã€‚
- **å¯Œæ–‡æœ¬è¯†åˆ«ï¼š** 
  - å…·å¤‡ä¼˜ç§€çš„æƒ…æ„Ÿè¯†åˆ«ï¼Œèƒ½å¤Ÿåœ¨æµ‹è¯•æ•°æ®ä¸Šè¾¾åˆ°å’Œè¶…è¿‡ç›®å‰æœ€ä½³æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹çš„æ•ˆæœã€‚
  - æ”¯æŒå£°éŸ³äº‹ä»¶æ£€æµ‹èƒ½åŠ›ï¼Œæ”¯æŒéŸ³ä¹ã€æŒå£°ã€ç¬‘å£°ã€å“­å£°ã€å’³å—½ã€å–·åšç­‰å¤šç§å¸¸è§äººæœºäº¤äº’äº‹ä»¶è¿›è¡Œæ£€æµ‹ã€‚
- **é«˜æ•ˆæ¨ç†ï¼š** SenseVoice-Smallæ¨¡å‹é‡‡ç”¨éè‡ªå›å½’ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œæ¨ç†å»¶è¿Ÿæä½ï¼Œ10séŸ³é¢‘æ¨ç†ä»…è€—æ—¶70msï¼Œ15å€ä¼˜äºWhisper-Largeã€‚
- **å¾®è°ƒå®šåˆ¶ï¼š** å…·å¤‡ä¾¿æ·çš„å¾®è°ƒè„šæœ¬ä¸ç­–ç•¥ï¼Œæ–¹ä¾¿ç”¨æˆ·æ ¹æ®ä¸šåŠ¡åœºæ™¯ä¿®å¤é•¿å°¾æ ·æœ¬é—®é¢˜ã€‚
- **æœåŠ¡éƒ¨ç½²ï¼š** å…·æœ‰å®Œæ•´çš„æœåŠ¡éƒ¨ç½²é“¾è·¯ï¼Œæ”¯æŒå¤šå¹¶å‘è¯·æ±‚ï¼Œæ”¯æŒå®¢æˆ·ç«¯è¯­è¨€æœ‰ï¼Œpythonã€c++ã€htmlã€javaä¸c#ç­‰ã€‚

# å®‰è£…ä¾èµ–ç¯å¢ƒ ğŸ

```shell
pip install -r requirements.txt
```

<a name="ç”¨æ³•æ•™ç¨‹"></a>
# ç”¨æ³• ğŸ› ï¸

## æ¨ç†



### ä½¿ç”¨funasræ¨ç†

æ”¯æŒä»»æ„æ ¼å¼éŸ³é¢‘è¾“å…¥ï¼Œæ”¯æŒä»»æ„æ—¶é•¿è¾“å…¥

```python
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess

model_dir = "FunAudioLLM/SenseVoiceSmall"


model = AutoModel(
    model=model_dir,
    trust_remote_code=True,
    vad_kwargs={"max_single_segment_time": 30000},
    device="cuda:0",
    hub="hf",
)

# en
res = model.generate(
    input=f"{model.model_path}/example/en.mp3",
    cache={},
    language="auto",  # "zn", "en", "yue", "ja", "ko", "nospeech"
    use_itn=True,
    batch_size_s=60,
    merge_vad=True,  #
    merge_length_s=15,
)
text = rich_transcription_postprocess(res[0]["text"])
print(text)
```
å‚æ•°è¯´æ˜ï¼š
- `model_dir`ï¼šæ¨¡å‹åç§°ï¼Œæˆ–æœ¬åœ°ç£ç›˜ä¸­çš„æ¨¡å‹è·¯å¾„ã€‚
- `device`(str)ï¼š `cuda:0`ï¼ˆé»˜è®¤gpu0ï¼‰ï¼Œä½¿ç”¨ GPU è¿›è¡Œæ¨ç†ï¼ŒæŒ‡å®šã€‚å¦‚æœä¸º`cpu`ï¼Œåˆ™ä½¿ç”¨ CPU è¿›è¡Œæ¨ç†ã€‚`mps`ï¼šmacç”µè„‘Mç³»åˆ—æ–°å“è¯•ç”¨mpsè¿›è¡Œæ¨ç†ã€‚`xpu`ï¼šä½¿ç”¨è‹±ç‰¹å°”gpuè¿›è¡Œæ¨ç†ã€‚
- `vad_model`ï¼šè¡¨ç¤ºå¼€å¯VADï¼ŒVADçš„ä½œç”¨æ˜¯å°†é•¿éŸ³é¢‘åˆ‡å‰²æˆçŸ­éŸ³é¢‘ï¼Œæ­¤æ—¶æ¨ç†è€—æ—¶åŒ…æ‹¬äº†VADä¸SenseVoiceæ€»è€—æ—¶ï¼Œä¸ºé“¾è·¯è€—æ—¶ï¼Œå¦‚æœéœ€è¦å•ç‹¬æµ‹è¯•SenseVoiceæ¨¡å‹è€—æ—¶ï¼Œå¯ä»¥å…³é—­VADæ¨¡å‹ã€‚
- `vad_kwargs`ï¼šè¡¨ç¤ºVADæ¨¡å‹é…ç½®,`max_single_segment_time`: è¡¨ç¤º`vad_model`æœ€å¤§åˆ‡å‰²éŸ³é¢‘æ—¶é•¿, å•ä½æ˜¯æ¯«ç§’msã€‚
- `use_itn`ï¼šè¾“å‡ºç»“æœä¸­æ˜¯å¦åŒ…å«æ ‡ç‚¹ä¸é€†æ–‡æœ¬æ­£åˆ™åŒ–ã€‚
- `batch_size_s` è¡¨ç¤ºé‡‡ç”¨åŠ¨æ€batchï¼Œbatchä¸­æ€»éŸ³é¢‘æ—¶é•¿ï¼Œå•ä½ä¸ºç§’sã€‚
- `merge_vad`ï¼šæ˜¯å¦å°† vad æ¨¡å‹åˆ‡å‰²çš„çŸ­éŸ³é¢‘ç¢ç‰‡åˆæˆï¼Œåˆå¹¶åé•¿åº¦ä¸º`merge_length_s`ï¼Œå•ä½ä¸ºç§’sã€‚

å¦‚æœè¾“å…¥å‡ä¸ºçŸ­éŸ³é¢‘ï¼ˆå°äº30sï¼‰ï¼Œå¹¶ä¸”éœ€è¦æ‰¹é‡åŒ–æ¨ç†ï¼Œä¸ºäº†åŠ å¿«æ¨ç†æ•ˆç‡ï¼Œå¯ä»¥ç§»é™¤vadæ¨¡å‹ï¼Œå¹¶è®¾ç½®`batch_size`

```python
model = AutoModel(model=model_dir, trust_remote_code=True, device="cuda:0", hub="hf")

res = model.generate(
    input=f"{model.model_path}/example/en.mp3",
    cache={},
    language="auto", # "zn", "en", "yue", "ja", "ko", "nospeech"
    use_itn=True,
    batch_size=64, 
)
```

æ›´å¤šè¯¦ç»†ç”¨æ³•ï¼Œè¯·å‚è€ƒ [æ–‡æ¡£](https://github.com/modelscope/FunASR/blob/main/docs/tutorial/README.md)







## `model`å‚æ•°

åœ¨ `AutoModel` çš„å®šä¹‰ä¸­ï¼Œ`model` å‚æ•°å®é™…ä¸Šæ˜¯ä¸€ä¸ªè·¯å¾„ï¼ˆ`path`ï¼‰ï¼Œå®ƒè¢«ä¼ é€’åˆ° `build_model` æ–¹æ³•ä¸­è¿›è¡Œå¤„ç†ã€‚ä»¥ä¸‹æ˜¯ `model` å‚æ•°ï¼ˆè·¯å¾„ï¼‰åœ¨ `AutoModel` ä¸­çš„å¤„ç†æµç¨‹ï¼š

---

### **1. `model` å‚æ•°çš„ä¼ é€’**
åœ¨å¤–éƒ¨è°ƒç”¨ä¸­ï¼Œ`model` è¢«ä¼ é€’ä¸ºä¸€ä¸ªè·¯å¾„å­—ç¬¦ä¸²ï¼ˆå¦‚ `model_dir`ï¼‰ï¼Œå¹¶é€šè¿‡ `kwargs` ä¼ é€’åˆ° `AutoModel` çš„æ„é€ å‡½æ•°ä¸­ï¼š

```python
model = AutoModel(
    model=model_dir,
    vad_model="fsmn-vad",
    vad_kwargs={"max_single_segment_time": 30000},
    device="cuda:0",
    hub="hf",
    disable_update=True,
)
```

åœ¨ `AutoModel` çš„ `__init__` æ–¹æ³•ä¸­ï¼Œ`kwargs` åŒ…å«äº† `model` å‚æ•°ï¼š

```python
model, kwargs = self.build_model(**kwargs)
self.model = model
```

---

### **2. `build_model` æ–¹æ³•çš„å¤„ç†**
`build_model` æ–¹æ³•æ˜¯å¤„ç† `model` å‚æ•°çš„æ ¸å¿ƒé€»è¾‘ã€‚ä»¥ä¸‹æ˜¯å…³é”®æ­¥éª¤ï¼š

#### **2.1 æ£€æŸ¥ `model` å‚æ•°**
`build_model` æ–¹æ³•é¦–å…ˆæ£€æŸ¥ `kwargs` ä¸­æ˜¯å¦åŒ…å« `model` å‚æ•°ï¼š

```python
assert "model" in kwargs
```

å¦‚æœ `model` å‚æ•°ä¸å­˜åœ¨ï¼Œåˆ™ä¼šæŠ›å‡ºå¼‚å¸¸ã€‚

#### **2.2 ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰**
å¦‚æœ `kwargs` ä¸­æ²¡æœ‰æä¾› `model_conf`ï¼Œåˆ™ä¼šå°è¯•ä»æ¨¡å‹ä¸­å¿ƒï¼ˆé»˜è®¤modelscopeï¼‰ä¸‹è½½æ¨¡å‹ï¼š

```python
if "model_conf" not in kwargs:
    logging.info("download models from model hub: {}".format(kwargs.get("hub", "ms")))
    kwargs = download_model(**kwargs)
```

- `download_model` æ–¹æ³•ä¼šæ ¹æ® `model` å‚æ•°ï¼ˆè·¯å¾„ï¼‰ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼Œå¹¶å°†ç›¸å…³é…ç½®æ›´æ–°åˆ° `kwargs` ä¸­ã€‚
- å¦‚æœ `model` æ˜¯ä¸€ä¸ªæœ¬åœ°è·¯å¾„ï¼Œåˆ™ç›´æ¥ä½¿ç”¨è¯¥è·¯å¾„ã€‚

#### **2.3 æ„å»ºæ¨¡å‹ç±»**
åœ¨ä¸‹è½½æˆ–åŠ è½½æ¨¡å‹é…ç½®åï¼Œ`build_model` æ–¹æ³•ä¼šæ ¹æ® `model` å‚æ•°çš„å€¼ï¼Œä»æ³¨å†Œè¡¨ä¸­è·å–å¯¹åº”çš„æ¨¡å‹ç±»ï¼š

```python
model_class = tables.model_classes.get(kwargs["model"])
assert model_class is not None, f'{kwargs["model"]} is not registered'
```

- `tables.model_classes` æ˜¯ä¸€ä¸ªæ³¨å†Œè¡¨ï¼Œå­˜å‚¨äº†æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹ç±»ã€‚
- `kwargs["model"]` æ˜¯æ¨¡å‹çš„åç§°æˆ–è·¯å¾„ï¼Œç”¨äºä»æ³¨å†Œè¡¨ä¸­æŸ¥æ‰¾å¯¹åº”çš„æ¨¡å‹ç±»ã€‚

#### **2.4 åˆå§‹åŒ–æ¨¡å‹**
æ‰¾åˆ°æ¨¡å‹ç±»åï¼Œ`build_model` æ–¹æ³•ä¼šä½¿ç”¨æ¨¡å‹é…ç½®ï¼ˆ`model_conf`ï¼‰åˆå§‹åŒ–æ¨¡å‹å®ä¾‹ï¼š

```python
model_conf = {}
deep_update(model_conf, kwargs.get("model_conf", {}))
deep_update(model_conf, kwargs)
model = model_class(**model_conf)
```

- `deep_update` æ–¹æ³•å°† `kwargs` ä¸­çš„é…ç½®åˆå¹¶åˆ° `model_conf` ä¸­ã€‚
- ä½¿ç”¨åˆå¹¶åçš„é…ç½®åˆå§‹åŒ–æ¨¡å‹ç±»ã€‚

#### **2.5 åŠ è½½é¢„è®­ç»ƒå‚æ•°**
å¦‚æœ `kwargs` ä¸­æä¾›äº† `init_param` å‚æ•°ï¼ˆé¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼‰ï¼Œåˆ™ä¼šåŠ è½½é¢„è®­ç»ƒå‚æ•°ï¼š

```python
init_param = kwargs.get("init_param", None)
if init_param is not None:
    if os.path.exists(init_param):
        logging.info(f"Loading pretrained params from {init_param}")
        load_pretrained_model(
            model=model,
            path=init_param,
            ignore_init_mismatch=kwargs.get("ignore_init_mismatch", True),
            oss_bucket=kwargs.get("oss_bucket", None),
            scope_map=kwargs.get("scope_map", []),
            excludes=kwargs.get("excludes", None),
        )
    else:
        print(f"error, init_param does not exist!: {init_param}")
```

#### **2.6 è®¾ç½®è®¾å¤‡**
æœ€åï¼Œ`build_model` æ–¹æ³•ä¼šå°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šçš„è®¾å¤‡ï¼ˆå¦‚ `cuda:0`ï¼‰ï¼š

```python
device = kwargs.get("device", "cuda")
if not torch.cuda.is_available() or kwargs.get("ngpu", 1) == 0:
    device = "cpu"
    kwargs["batch_size"] = 1
kwargs["device"] = device
model.to(device)
```

---

### **3. æ€»ç»“**
`model` å‚æ•°ï¼ˆè·¯å¾„ï¼‰åœ¨ `AutoModel` ä¸­çš„å¤„ç†æµç¨‹å¦‚ä¸‹ï¼š

1. **ä¼ é€’åˆ° `build_model` æ–¹æ³•**ï¼š
   - `model` å‚æ•°ä½œä¸ºè·¯å¾„å­—ç¬¦ä¸²ï¼Œé€šè¿‡ `kwargs` ä¼ é€’åˆ° `build_model` æ–¹æ³•ã€‚

2. **ä¸‹è½½æˆ–åŠ è½½æ¨¡å‹**ï¼š
   - å¦‚æœ `model` æ˜¯ä¸€ä¸ªè¿œç¨‹è·¯å¾„ï¼ˆå¦‚ Hugging Face Hub çš„æ¨¡å‹åç§°ï¼‰ï¼Œåˆ™ä¼šä¸‹è½½æ¨¡å‹æ–‡ä»¶ã€‚
   - å¦‚æœ `model` æ˜¯ä¸€ä¸ªæœ¬åœ°è·¯å¾„ï¼Œåˆ™ç›´æ¥åŠ è½½ã€‚

3. **æŸ¥æ‰¾æ¨¡å‹ç±»**ï¼š
   - æ ¹æ® `model` å‚æ•°çš„å€¼ï¼Œä»æ³¨å†Œè¡¨ä¸­æŸ¥æ‰¾å¯¹åº”çš„æ¨¡å‹ç±»ã€‚

4. **åˆå§‹åŒ–æ¨¡å‹**ï¼š
   - ä½¿ç”¨ `kwargs` ä¸­çš„é…ç½®åˆå§‹åŒ–æ¨¡å‹å®ä¾‹ã€‚

5. **åŠ è½½é¢„è®­ç»ƒå‚æ•°**ï¼š
   - å¦‚æœæä¾›äº†é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼Œåˆ™åŠ è½½é¢„è®­ç»ƒå‚æ•°ã€‚

6. **è®¾ç½®è®¾å¤‡**ï¼š
   - å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šçš„è®¾å¤‡ï¼ˆå¦‚ GPU æˆ– CPUï¼‰ã€‚

æœ€ç»ˆï¼Œå¤„ç†åçš„æ¨¡å‹å®ä¾‹è¢«è¿”å›å¹¶èµ‹å€¼ç»™ `self.model`ï¼Œä¾›åç»­æ¨ç†æˆ–è®­ç»ƒä½¿ç”¨ã€‚



## ç›´æ¥æ¨ç†

æ”¯æŒä»»æ„æ ¼å¼éŸ³é¢‘è¾“å…¥ï¼Œè¾“å…¥éŸ³é¢‘æ—¶é•¿é™åˆ¶åœ¨30sä»¥ä¸‹

```python
from model import SenseVoiceSmall
from funasr.utils.postprocess_utils import rich_transcription_postprocess

model_dir = "FunAudioLLM/SenseVoiceSmall"
m, kwargs = SenseVoiceSmall.from_pretrained(model=model_dir, device="cuda:0", hub="hf")
m.eval()

res = m.inference(
    data_in=f"{kwargs['model_path']}/example/en.mp3",
    language="auto", # "zn", "en", "yue", "ja", "ko", "nospeech"
    use_itn=False,
    **kwargs,
)

text = rich_transcription_postprocess(res[0][0]["text"])
print(text)
```




## WebUI

```shell
python webui.py
```



